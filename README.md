# Low Resource Neural Machine Translation
## Project for NLP2 course at UVA (2025)

The goal of this project is to revisit domain adaptation of small NMT systems and try to apply SoTA methods to improve the translation quality when the number of in-domain parallel samples is limited.


# 1. ‚öôÔ∏è Setup

## 1.1 Install environment

```
# install env (done already)
sbatch install_environment.job
```

## 1.2 Run interactive shell job
To use Python scripts or Jupyter notebooks. It was easier for us to run some experiments in an interactive shell than in sbatch jobs.

```
# interactive job, 2/4th of a node
srun --partition=gpu_a100 --gpus=1 --ntasks=1 --cpus-per-task=18 --time=02:00:00 --pty bash -i
module purge
module load 2022
module load Anaconda3/2022.05
source activate nmt
```

## 1.3 Start jupyter notebook

```
# start jupyter notebook
jupyter-notebook --no-browser --ip=0.0.0.0 --port 8888

# Install all necessary VSCode Jupyter extensions  

# select in vscode: select kernel, existing Jupyter server, paste the link containing "gcn"
```
# 2. üß™ Research questions and their code

## 2.0 Initial hyperparameters tuning
We did some initial hyperparameter tuning and search before running all other experiments.

```
scripts/optimize.py - main hyperparam search script
optimize_job.py - job to start hyperparam search
```

## 2.1 Fine-tuning vs Back-translation
We fine-tuned the baseline model on parallel data, as well as on backtranslated data. The backtranslation model was fine-tuned as well.

```
scripts/finetune_one_model.py - to finetune selected model on parallel data
scripts/backtranslate.py - code to backtranslate selected datapoints using selected model
backtranslate_data.job - slurm job to backtranslate
scripts/evaluate_test.py - to evaluate model on all our test datasets
evaluate_test.job - slurm job to evaluate model
```

## 2.2 Embedding-based data selection
We calculated OpenAI embeddings and performed outlier analysis. We used this signal to filter out outliers

```
make_dataset_smaller_rq2.ipynb - enrich data with embeddings, outlier score, perform analysis and save dataset copies with no outliers
scripts/finetune_one_model.py - to finetune selected model on parallel (filtered) data
scripts/evaluate_test.py - to evaluate model on all our test datasets
evaluate_test.job - slurm job to evaluate model
```

## 2.3 Uncertainty-aware selective fine-tuning and generation

```
generation_entropy_experiment.ipynb - to test the semantic entropy method
backtranslate_with_semantic_entropy.py - to generate back-translated data with uncertainty signal

scripts/finetune_one_model.py - to finetune selected model on parallel (filtered) data with optional (commented-out) uncertainty filtering
scripts/evaluate_test.py - to evaluate model on all our test datasets
evaluate_test.job - slurm job to evaluate model

evaluation_entropy_experiment.ipynb - to test the impact of selective forward-translation on the metrics
```

## 2.4  LLM-based variations generation

```
rq4_calibration_set.ipynb - to generate set of 1000 samples with COMET scores to generate variations of

generation of synthetic data:  fill this in in repo

finetune_one_model_with_extra_synthetic_data.py - script to finetune with both original and synthetic parallel data
scripts/evaluate_test.py - to evaluate model on all our test datasets
evaluate_test.job - slurm job to evaluate model
```

