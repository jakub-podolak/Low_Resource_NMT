{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration = pd.read_csv('results/datasets/rq4/medline_1000_calibration_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini-2025-04-14\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration.sort_values(by='comet_score', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_250 = calibration.head(n=250)\n",
    "bottom_500 =calibration.head(n=500)\n",
    "top_250 = calibration.tail(n=250)\n",
    "top_500 = calibration.tail(n=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3 = calibration.head(3)\n",
    "top_3.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3 = top_3[['en', 'ru']]\n",
    "for i in range(len(top_3)):\n",
    "    en_list =[]\n",
    "    ru_list = []\n",
    "    eng = top_3.iloc[i]['en']\n",
    "    rus = top_3.iloc[i]['ru']\n",
    "    prompt = (\n",
    "        \"Here is an example of a snippet of biomedical text in English and its \"\n",
    "        f\"translation into Russian:\\n\\nEN: {eng}\\nRU: {rus}\\n\\n\"\n",
    "        \"Based on this example, be creative and generate an entirely new pair of snippets.\"\n",
    "        \"Return only valid JSON with no markdown  in the form \"\n",
    "        '{\"en\": \"<novel-english-snippet>\", \"ru\": \"<russian-translation-of-novel-snippet>\"}.'\n",
    "    )\n",
    "    response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini-2025-04-14\",\n",
    "    input=prompt)   \n",
    "\n",
    "    pair = json.loads(response.output_text)\n",
    "    en_list.append(pair['en'])\n",
    "    ru_list.append(pair['ru'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_pairs(input_pairs, synth_per_pair = 2):\n",
    "    input_pairs = input_pairs[['en', 'ru']]\n",
    "    en_list =[]\n",
    "    ru_list = []\n",
    "    failed_list = []\n",
    "    for i in range(len(input_pairs)):\n",
    "        for j in range(synth_per_pair):\n",
    "            eng = input_pairs.iloc[i]['en']\n",
    "            rus = input_pairs.iloc[i]['ru']\n",
    "            prompt = (\n",
    "                \"Here is an example of a snippet of biomedical text in English and its \"\n",
    "                f\"translation into Russian:\\n\\nEN: {eng}\\nRU: {rus}\\n\\n\"\n",
    "                \"Based on this example, be creative and generate an entirely new pair of snippets.\"\n",
    "                \"Return only valid JSON with no markdown in the form \"\n",
    "                '{\"en\": \"<novel-english-snippet>\", \"ru\": \"<russian-translation-of-novel-snippet>\"}.'\n",
    "            )\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4.1-mini-2025-04-14\",\n",
    "                input=prompt,\n",
    "                    \n",
    "            )   \n",
    "            try:\n",
    "                pair = json.loads(response.output_text)\n",
    "                en_list.append(pair['en'])\n",
    "                ru_list.append(pair['ru'])    \n",
    "            except:\n",
    "                failed_list.append(response)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "    'synth_en': en_list,\n",
    "    'synth_ru': ru_list\n",
    "    })\n",
    "    return df, failed_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_bottom_250, _ = generate_synthetic_pairs(bottom_250, synth_per_pair=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_bottom_250.to_csv('../results/datasets/medline_calibration_bottom_250_4x.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
